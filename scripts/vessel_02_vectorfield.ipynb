{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ca8588-929b-422c-8011-1d8bfc2a6cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import data, io\n",
    "from skimage.filters import threshold_otsu\n",
    "import os\n",
    "import imageio\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import napari\n",
    "import tifffile\n",
    "from scipy import spatial\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import normalize, PolynomialFeatures\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73ba5c52-9ee0-4584-9c25-ff6ca9bc3294",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threadpoolctl import threadpool_limits\n",
    "import ray\n",
    "# num_cpus=48\n",
    "# ray.init(num_cpus=num_cpus, ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c118ef00-20ae-4fb0-bcef-739ed08c6030",
   "metadata": {},
   "outputs": [],
   "source": [
    "io_directory = '/mnt/ampa_data01/tmurakami/220305_SMA_nuc_middlehuman/vessel_analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15133a6a-4152-484a-b25b-9a0793773bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 819, 546)\n"
     ]
    }
   ],
   "source": [
    "asma_downscale = np.load(os.path.join(io_directory,'vessel.npy'))\n",
    "dim = asma_downscale.ndim\n",
    "print(asma_downscale.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7314142a-5b0f-4918-9fc4-06e4c1138be8",
   "metadata": {},
   "source": [
    "### If meninge mask are required, make it using labkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fee6adac-81ed-4c83-85d2-f96aa9774c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_meninge = 1 - tifffile.imread(os.path.join(io_directory,'meninge.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be8b5a31-bf8b-4f59-af60-1739f257d5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare mask. This time, use mask prepared with ClearMap.\n",
    "mask = np.load(os.path.join(io_directory,'binary_final.npy'))#np.load('/scratch2/Share/tmurakami/220121_human_sma_5mm_1st/vessel/binary_final.npy')\n",
    "# mask = mask * mask_meninge\n",
    "mask_1d = mask.flatten()\n",
    "\n",
    "# Extract the vectors and positions using mask.\n",
    "points_position_array = np.array(np.where(mask)).T\n",
    "points_position = points_position_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb696a4f-b73b-4147-bb7f-aa612ebe3eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually design your guide vector\n",
    "# To Do: automation of the vector detection.\n",
    "guide_coordinate1 = np.array([237.,145.,405.])\n",
    "guide_coordinate2 = np.array([201.,181.,373.])\n",
    "guide_vector = guide_coordinate2 - guide_coordinate1\n",
    "guide_vector = guide_vector / np.linalg.norm(guide_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b07d0c0-3a22-4e56-9838-6f3bf0781ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare skeleton. Use the skeleton prepared with ClearMap.\n",
    "skeleton = np.load(os.path.join(io_directory,'skeleton.npy'))\n",
    "# skeleton = skeleton * mask_meninge\n",
    "skeleton_1d = skeleton.flatten()\n",
    "\n",
    "# Extract the position of the skeleton for the vector field analysis.\n",
    "skeleton_position_array = np.array(np.where(skeleton)).T\n",
    "skeleton_position = skeleton_position_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b5c1288-d4a4-42e6-a686-fe3304eae5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_vector_sign(vectors, guide_vector=None):\n",
    "    '''\n",
    "    Align the sign of the vector by refering a guide vector. If the dot product of the vector and the guide vector is negative, the sign of vector is flipped.\n",
    "    Highly encourage to make a guide vector before align sign.\n",
    "    '''\n",
    "    if (guide_vector is None):\n",
    "        guide_vector = normalize(np.median(vectors,axis=0)[:,np.newaxis],axis=0).ravel()\n",
    "    aligned_vectors = np.where(\n",
    "        np.repeat(np.expand_dims(np.matmul(vectors, guide_vector) >= 0, axis=1), guide_vector.size, axis=1),\n",
    "        vectors,\n",
    "        -vectors\n",
    "    )\n",
    "    return aligned_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a48e5ba-2fc6-4510-8266-bdbf7655c32e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vector field analysis on skeleton using neighbors.\n",
    "kdtree = spatial.KDTree(skeleton_position_array)\n",
    "k = 27 # Number of neighbors.\n",
    "mean_skeleton_vectors = []\n",
    "\n",
    "for point, point_position in enumerate(skeleton_position):\n",
    "    # Extract vectors from k-nearest neighbors.\n",
    "    d, neighbors = kdtree.query(point_position,k)\n",
    "    neighbors = neighbors[d!=0]\n",
    "    vectors_from_neighbors = normalize(skeleton_position_array[neighbors,:]-point_position,axis=1) # Normalize to equalize the weights\n",
    "    mean_vector = np.mean(align_vector_sign(vectors_from_neighbors,guide_vector),axis=0) # Use arithmetic mean.\n",
    "    mean_vector = normalize(mean_vector[:,np.newaxis],axis=0).ravel()\n",
    "    mean_skeleton_vectors.append(mean_vector)\n",
    "mean_skeleton_vectors = np.array(mean_skeleton_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1248154-a920-4ec0-a446-984fbf306037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expansion of vector field to binarized image.\n",
    "kdtree = spatial.KDTree(skeleton_position_array)\n",
    "k = 1 # Number of neighbors in skeleton.\n",
    "point_vectors = []\n",
    "\n",
    "for point, point_position in enumerate(points_position):\n",
    "    _, neighbors = kdtree.query(point_position,k)\n",
    "    neighbor_vector = mean_skeleton_vectors[neighbors]\n",
    "#     if k > 1:\n",
    "#         mean_neighbor_vectors =np.mean(neighbor_vector,axis=0)\n",
    "#         neighbor_vector = normalize(mean_neighbor_vectors[:,np.newaxis],axis=0).ravel()\n",
    "    point_vectors.append(neighbor_vector)\n",
    "point_vectors = np.array(point_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c170ac45-c0aa-4787-9aed-ddd437999af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Start denoising'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1426401a-6b91-4acc-bded-1e2f5de8324e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def get_neighbor_vectors(point_position, kdtree, vectors, radius):\n",
    "    if not isinstance(point_position, np.ndarray):\n",
    "        point_position = np.array(point_position)\n",
    "    neighbors = kdtree.query_ball_point(point_position,radius)\n",
    "    neighbor_vectors = vectors[neighbors,:]\n",
    "    return neighbor_vectors\n",
    "\n",
    "@ray.remote\n",
    "def get_median_vector(vectors):\n",
    "    # Ideally, the medoid vector should be calculated, but it is resource demanding. Instead, calculate the median in each dimension and normalize to a unit vector.\n",
    "    \"\"\"\n",
    "    vectors: ndarray\n",
    "    \"\"\"\n",
    "    median_vector = normalize(np.median(vectors,axis=0)[:,np.newaxis],axis=0).ravel()\n",
    "    return median_vector\n",
    "\n",
    "@ray.remote\n",
    "def get_point_vector(point, vectors):\n",
    "    return vectors[point]\n",
    "\n",
    "@ray.remote\n",
    "def single_thread_align_vector_sign(vectors, guide_vector):\n",
    "    '''\n",
    "    Align the sign of the vector by refering a guide vector. If the dot product of the vector and the guide vector is negative, the sign of vector is flipped.\n",
    "    '''\n",
    "    with threadpool_limits(limits=1, user_api='blas'):\n",
    "        aligned_vectors = np.where(\n",
    "            np.repeat(np.expand_dims(np.matmul(vectors, guide_vector) >= 0, axis=1), guide_vector.size, axis=1),\n",
    "            vectors,\n",
    "            -vectors\n",
    "        )\n",
    "    return aligned_vectors\n",
    "\n",
    "@ray.remote\n",
    "def select_point_in_dot_product_space(point_vector, neighbor_vectors, median_vector, k=10):\n",
    "    with threadpool_limits(limits=1, user_api='blas'):\n",
    "        # Calculate the dot product\n",
    "        dot_product = np.matmul(neighbor_vectors, median_vector) # This is done in parallel otherwise stated.\n",
    "        dot_product_of_point = np.matmul(point_vector,median_vector)\n",
    "    if k>dot_product.size:\n",
    "        selection = False\n",
    "    else:\n",
    "        # Find k neighbors in dot product space\n",
    "        dot_product_neighbors = dot_product[np.argsort(np.abs(dot_product-dot_product_of_point))][0:k]\n",
    "        # Calculate the null density if the density is even distribution.\n",
    "        null_density = dot_product.size*(dot_product_neighbors.max()-dot_product_neighbors.min())\n",
    "        selection = (k>null_density)\n",
    "    # Second selection using otsu thresholding\n",
    "    if selection:\n",
    "        thresh = threshold_otsu(dot_product)\n",
    "        selection = (dot_product_of_point>thresh)\n",
    "    return selection\n",
    "\n",
    "@ray.remote\n",
    "def dot_product_vectors(vector1, vector2):\n",
    "    with threadpool_limits(limits=1, user_api='blas'):\n",
    "        dot_product = np.matmul(vector1, vector2)\n",
    "    return dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2498680a-6366-4184-ad06-a2d8c3499e8c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(get_median_vector pid=605365)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_neighbor_vectors pid=605298)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_neighbor_vectors pid=605415)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_point_vector pid=605362)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_median_vector pid=605452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(select_point_in_dot_product_space pid=605358)\u001b[0m \n",
      "\u001b[2m\u001b[36m(select_point_in_dot_product_space pid=605433)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_median_vector pid=605355)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_point_vector pid=605350)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_neighbor_vectors pid=605388)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_point_vector pid=605380)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_neighbor_vectors pid=605357)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_neighbor_vectors pid=605356)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_median_vector pid=605457)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_neighbor_vectors pid=605378)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_point_vector pid=605423)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_median_vector pid=605343)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_median_vector pid=605410)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_neighbor_vectors pid=605299)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_median_vector pid=605457)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_median_vector pid=605354)\u001b[0m \n",
      "\u001b[2m\u001b[36m(single_thread_align_vector_sign pid=605359)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_neighbor_vectors pid=605418)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_median_vector pid=605354)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_neighbor_vectors pid=605371)\u001b[0m \n",
      "\u001b[2m\u001b[36m(single_thread_align_vector_sign pid=605380)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_point_vector pid=605388)\u001b[0m \n",
      "\u001b[2m\u001b[36m(select_point_in_dot_product_space pid=605367)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_point_vector pid=605371)\u001b[0m \n",
      "\u001b[2m\u001b[36m(single_thread_align_vector_sign pid=605367)\u001b[0m \n",
      "\u001b[2m\u001b[36m(select_point_in_dot_product_space pid=605388)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_median_vector pid=605386)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_neighbor_vectors pid=605405)\u001b[0m \n",
      "\u001b[2m\u001b[36m(select_point_in_dot_product_space pid=605423)\u001b[0m \n",
      "\u001b[2m\u001b[36m(single_thread_align_vector_sign pid=605457)\u001b[0m \n",
      "\u001b[2m\u001b[36m(single_thread_align_vector_sign pid=605343)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_median_vector pid=605399)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_median_vector pid=605468)\u001b[0m \n",
      "\u001b[2m\u001b[36m(select_point_in_dot_product_space pid=605468)\u001b[0m \n",
      "\u001b[2m\u001b[36m(select_point_in_dot_product_space pid=605400)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_median_vector pid=605448)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_median_vector pid=605361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(select_point_in_dot_product_space pid=605468)\u001b[0m \n",
      "\u001b[2m\u001b[36m(select_point_in_dot_product_space pid=605418)\u001b[0m \n",
      "\u001b[2m\u001b[36m(get_median_vector pid=605345)\u001b[0m \n",
      "\u001b[2m\u001b[36m(single_thread_align_vector_sign pid=605356)\u001b[0m \n",
      "\u001b[2m\u001b[36m(single_thread_align_vector_sign pid=605351)\u001b[0m \n",
      "\u001b[2m\u001b[36m(single_thread_align_vector_sign pid=605441)\u001b[0m \n",
      "\u001b[2m\u001b[36m(single_thread_align_vector_sign pid=605384)\u001b[0m \n",
      "\u001b[2m\u001b[36m(select_point_in_dot_product_space pid=605408)\u001b[0m \n",
      "\u001b[2m\u001b[36m(select_point_in_dot_product_space pid=605378)\u001b[0m \n",
      "\u001b[2m\u001b[36m(select_point_in_dot_product_space pid=605365)\u001b[0m \n",
      "CPU times: user 5min 47s, sys: 55.5 s, total: 6min 43s\n",
      "Wall time: 3min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kdtree = spatial.KDTree(points_position_array)\n",
    "radius = 42 # pixel unit. 500 / voxel micrometer works well. diameter in real scale: 2 * radius * voxelsize. \n",
    "k = 10 # Number of neighbor in dot product space. Note this is not a number of neighbor in 3D image space.\n",
    "keeping = []\n",
    "# dot_p = []\n",
    "\n",
    "kdtree_id = ray.put(kdtree)\n",
    "vectors_id = ray.put(point_vectors)\n",
    "\n",
    "for point, point_position in enumerate(points_position):\n",
    "    point_vector = get_point_vector.remote(point, vectors_id)\n",
    "    # Get vectors in neighbor points.\n",
    "    neighbor_vectors = get_neighbor_vectors.remote(point_position, kdtree_id, vectors_id, radius)\n",
    "    # Make representitive vector\n",
    "    median_vector = get_median_vector.remote(neighbor_vectors)\n",
    "    neighbor_vectors = single_thread_align_vector_sign.remote(neighbor_vectors, median_vector) # Fix the sign of vectors.\n",
    "\n",
    "    keeping.append(select_point_in_dot_product_space.remote(point_vector, neighbor_vectors, median_vector, k))\n",
    "    # dot_p.append(dot_product_vectors.remote(point_vector,median_vector))\n",
    "\n",
    "keeping = ray.get(keeping)\n",
    "extract_idx = np.where(mask_1d)[0][keeping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d6d7d0c-f28b-45ed-8355-e6b008d6df6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False: # True to save images and variables for later use.\n",
    "    vec_img = np.zeros(asma_downscale.shape+(dim,)).astype(np.float32)\n",
    "    extracted = points_position_array[keeping]\n",
    "    vec_img[tuple(extracted.T)] = point_vectors[keeping,:]\n",
    "    \n",
    "    # export extracted vetors as image\n",
    "    tifffile.imwrite(os.path.join(io_directory,'local_vector.tif'),\n",
    "                 np.moveaxis(vec_img,-1,1).astype(np.float32),\n",
    "                 imagej=True,\n",
    "                 metadata={'spacing': 12, 'unit': 'um', 'axes': 'ZCYX'})\n",
    "    \n",
    "    # save variables as .npy\n",
    "    np.save(os.path.join(io_directory,'extract_idx.npy'), extract_idx)\n",
    "    np.save(os.path.join(io_directory,'point_vectors.npy'), point_vectors)\n",
    "    np.save(os.path.join(io_directory,'keeping.npy'), np.asarray(keeping))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37854618-4827-4f35-a5d8-5bb093ceb425",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c51ea972-7991-4308-b5ff-e5432193531d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(fit_intercept=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit to the nth polynomial\n",
    "degree = 5\n",
    "idx = np.array(np.unravel_index(extract_idx,asma_downscale.shape)).T\n",
    "vec = point_vectors[keeping,:]\n",
    "poly = PolynomialFeatures(degree=degree) # Overfitting may happen at the edge?\n",
    "idx_ = poly.fit_transform(idx)\n",
    "\n",
    "clf = linear_model.LinearRegression(fit_intercept=False) # False\n",
    "clf.fit(idx_,vec)# Fit the model\n",
    "clf.degree = degree# save information for polynomial degree for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f08214c-83e3-42bc-8365-3ac4f54e42b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/mnt/ampa_data01/tmurakami/220305_SMA_nuc_middlehuman/vessel_analysis/model.pkl'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e26b786-9c67-4f2b-9b1a-c414d9a95ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the vector field as image if it is required.\n",
    "if False: # honestly, the interpretation is difficult and does not help much.\n",
    "    all_coord = np.indices(asma_downscale.shape)\n",
    "    all_coord = np.stack([all_coord[i,:,:,:].flatten() for i in range(dim)], axis=1).astype(int)\n",
    "    all_coord_ = poly.fit_transform(all_coord)\n",
    "\n",
    "    fit_img = clf.predict(all_coord_)\n",
    "    fit_img = fit_img.reshape(asma_downscale.shape+(dim,))\n",
    "    vector_field_tif = os.path.join(io_directory,'vector_field_interpolation.tif')\n",
    "\n",
    "    # export extracted vetors as image\n",
    "    tifffile.imwrite(vector_field_tif,\n",
    "             np.moveaxis(fit_img,-1,1).astype(np.float32),\n",
    "             imagej=True,\n",
    "             metadata={'spacing': 10, 'unit': 'um', 'axes': 'ZCYX'})\n",
    "    del(all_coord)\n",
    "    del(all_coord_)\n",
    "    del(fit_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fab0b90-75bc-43b1-8836-59ac20ec93d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218925"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(keeping).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004fd7d5-4928-4a2b-a5f0-2a27f1ef528f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segment",
   "language": "python",
   "name": "segment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
